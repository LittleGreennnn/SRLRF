{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f9d5a-a2d3-4f15-96ce-b00bcc7a08f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/soft-label/train-dataset-code-split.csv')\n",
    "test_data = pd.read_csv('data/soft-label/test-dataset-code-split.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 定义超参数搜索范围\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],        # 森林中的树数量\n",
    "    'max_depth': [None, 10, 20, 30],            # 树的最大深度\n",
    "    'min_samples_split': [2, 5, 10],            # 内部节点再分裂所需最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4],              # 叶子节点的最小样本数\n",
    "    'class_weight': [None, 'balanced']          # 是否平衡类别权重\n",
    "}\n",
    "\n",
    "# 初始化 RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", grid_search.best_params_)\n",
    "print(\"最佳得分: \", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳模型进行测试集评估\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估结果\n",
    "print(\"测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred,digits=4))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ff2a9-aee6-4fd9-81c8-eb54502a0b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/soft-label/train-dataset-softlabels.csv')\n",
    "test_data = pd.read_csv('data/soft-label/test-dataset-softlabels.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 定义超参数搜索范围\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],        # 正则化强度\n",
    "    'solver': ['liblinear', 'lbfgs'],    # 优化算法\n",
    "    'class_weight': [None, 'balanced']   # 类别权重\n",
    "}\n",
    "\n",
    "# 初始化 LogisticRegression 模型\n",
    "lr = LogisticRegression(max_iter=500, random_state=42)\n",
    "\n",
    "# 使用 GridSearchCV 进行超参数搜索\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", grid_search.best_params_)\n",
    "print(\"最佳得分: \", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳模型进行测试集评估\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 输出分类报告和测试集准确率\n",
    "print(\"\\n测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred,digits=4))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db645ee-481c-490f-81d3-d1d5f63bf05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/soft-label/train-dataset-softlabels.csv')\n",
    "test_data = pd.read_csv('data/soft-label/test-dataset-softlabels.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 定义随机搜索参数范围\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 10),\n",
    "    'subsample': np.linspace(0.6, 1.0, 5),\n",
    "    'colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "    'gamma': np.linspace(0, 0.5, 5),\n",
    "    'reg_alpha': [0, 0.1, 1, 10],\n",
    "    'reg_lambda': [1, 10, 100]\n",
    "}\n",
    "\n",
    "# 初始化 XGBoost 模型\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# 使用 RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_distributions, \n",
    "                                   n_iter=100, scoring='accuracy', cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# 执行随机搜索\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", random_search.best_params_)\n",
    "print(\"最佳得分: \", random_search.best_score_)\n",
    "\n",
    "# 使用最佳模型评估测试集\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8a23f-a31f-436c-8841-78028e980bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/soft-label/train-dataset-softlabels.csv')\n",
    "test_data = pd.read_csv('data/soft-label/test-dataset-softlabels.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 定义超参数搜索范围\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 52, 2)),  # 1 到 51 的奇数\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\n",
    "    'p': [1, 2, 3]  # Minkowski 距离参数\n",
    "}\n",
    "\n",
    "# 初始化 KNN 模型\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 使用 GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 执行搜索\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", grid_search.best_params_)\n",
    "print(\"最佳得分: \", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳模型进行测试集评估\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# 评估结果\n",
    "print(\"\\n测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889a051-16f5-4d27-8f60-f83aadd14e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta-0','rta-1','rta-2','rta-3','rta-4','rta-5','rta-6','rta-7',\n",
    "                      'llama-0','llama-1','llama-2','llama-3','llama-4','llama-5','llama-6','llama-7']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 定义超参数搜索范围\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 'scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# 初始化 SVM 模型\n",
    "svm = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# 选择搜索方式：GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# 执行搜索\n",
    "print(\"开始执行 GridSearchCV 超参数调优...\")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", grid_search.best_params_)\n",
    "print(\"最佳交叉验证得分: \", grid_search.best_score_)\n",
    "\n",
    "# 使用最佳模型进行测试集评估\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# 输出分类报告和测试集准确率\n",
    "print(\"\\n测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1995cefd-82c8-46a1-9f6b-77d53ff35df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from functools import partial\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/ensemble/stacking/stacking_train_dataset.csv')\n",
    "test_data = pd.read_csv('data/ensemble/stacking/stacking_test_dataset.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta_prediction', 'llama_prediction']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta_prediction', 'llama_prediction']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 定义目标函数\n",
    "def objective(trial, X_train, y_train, X_test, y_test, n_repeats=5):\n",
    "    # 定义超参数搜索空间\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    for _ in range(n_repeats):  # 多次运行并取平均值\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)  # 返回平均得分\n",
    "\n",
    "# 创建 Optuna 优化器\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(partial(objective, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test), n_trials=50)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", study.best_params)\n",
    "print(\"最佳平均得分: \", study.best_value)\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "best_params = study.best_params\n",
    "best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 评估结果\n",
    "print(\"测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e96df9-8232-4c3a-84ad-cbe6c5933bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from functools import partial\n",
    "\n",
    "# 加载数据\n",
    "train_data = pd.read_csv('data/ensemble/stacking/stacking_train_dataset.csv')\n",
    "test_data = pd.read_csv('data/ensemble/stacking/stacking_test_dataset.csv')\n",
    "\n",
    "# 提取元特征和标签\n",
    "X_train = train_data[['rta_prediction', 'llama_prediction']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['rta_prediction', 'llama_prediction']]\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 定义目标函数\n",
    "def objective(trial, X_train, y_train, X_test, y_test, n_repeats=5):\n",
    "    # 定义超参数搜索空间\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 101, step=2)  # 奇数1到51\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'chebyshev', 'minkowski'])\n",
    "    p = trial.suggest_int('p', 1, 5)  # Minkowski 距离的p参数\n",
    "\n",
    "    # 多次运行取平均值\n",
    "    scores = []\n",
    "    for _ in range(n_repeats):\n",
    "        knn = KNeighborsClassifier(\n",
    "            n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            metric=metric,\n",
    "            p=p\n",
    "        )\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)  # 返回平均测试准确率\n",
    "\n",
    "# 使用 Optuna 进行超参数优化\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(partial(objective, X_train=X_train_scaled, y_train=y_train, \n",
    "                       X_test=X_test_scaled, y_test=y_test), \n",
    "               n_trials=100)\n",
    "\n",
    "# 输出最佳参数和得分\n",
    "print(\"最佳参数: \", study.best_params)\n",
    "print(\"最佳平均得分: \", study.best_value)\n",
    "\n",
    "# 使用最佳参数重新训练模型\n",
    "best_params = study.best_params\n",
    "best_knn = KNeighborsClassifier(\n",
    "    n_neighbors=best_params['n_neighbors'],\n",
    "    weights=best_params['weights'],\n",
    "    metric=best_params['metric'],\n",
    "    p=best_params['p']\n",
    ")\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# 评估结果\n",
    "print(\"\\n测试集分类报告：\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0300d-790e-4c79-827c-afa94241c708",
   "metadata": {},
   "source": [
    "# sklearn库 MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4c4f5-1b25-4d32-b1bc-1c99a613397a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "\n",
    "# 1. 加载数据集\n",
    "train_data = pd.read_csv('data/soft-label/train-dataset-softlabels.csv')\n",
    "test_data = pd.read_csv('data/soft-label/test-dataset-softlabels.csv')\n",
    "\n",
    "# 2. 数据预处理\n",
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "# 标准化特征（很重要，MLP对数据缩放敏感）\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 3. 定义MLPClassifier模型\n",
    "mlp = MLPClassifier(max_iter=4000, random_state=42)\n",
    "\n",
    "# 4. 超参数调优\n",
    "# 动态生成 hidden_layer_sizes 参数\n",
    "hidden_layer_sizes = []\n",
    "neuron_options = [16, 32, 64, 128]\n",
    "for layers in range(1, 4):  # 隐藏层数：1层、2层、3层\n",
    "    for combination in itertools.product(neuron_options, repeat=layers):\n",
    "        hidden_layer_sizes.append(combination)\n",
    "# 定义超参数网格\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'alpha': [1e-5, 0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# 使用GridSearchCV进行超参数搜索\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "# 打印最佳参数\n",
    "print(\"最佳超参数：\", grid_search.best_params_)\n",
    "\n",
    "# 5. 评估模型\n",
    "# 在测试集上进行预测\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# 输出评估指标\n",
    "print(\"分类报告：\\n\", classification_report(y_test, y_pred))\n",
    "print(\"混淆矩阵：\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"准确率：\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89eae5-f3b2-4dcf-bae7-ee2e67070c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fe42a-0416-4129-a418-84af055448cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
