{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec7bdb-63aa-419a-9b39-2b3eac823649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练好的Llama3.1模型生成元特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cea0b-00cf-4061-83aa-881480d3e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载原始模型\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 5000\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"model/LLM-Research/Meta-Llama-3___1-8B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50232b-d5a8-4aaf-9d04-754d8fa97e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载lora适配器\n",
    "from peft import PeftModel\n",
    "lora_path = 'save/Llama3.1-ensemble-v2'\n",
    "model = PeftModel.from_pretrained(model, lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bc2e7-38a6-431a-a0da-c6e282d90e6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171a48a-26ef-4bf1-a57c-f1292589bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载测试集\n",
    "from datasets import load_dataset\n",
    "test_dataset = load_dataset('csv', data_files='data/dataset_5fold_1/dataset_fold_5.csv', split='train')\n",
    "test_dataset = test_dataset.remove_columns([\"text\",\"label\"])\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684fd64e-4823-4d64-8362-60560e3fc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 4500  # Llama3.1支持128k上下文\n",
    "\n",
    "def truncate(data_point):\n",
    "    # 构建初始的 full_prompt\n",
    "    full_prompt = f\"\"\"You are a developer of the GCC compiler. Your job is to categorize bug reports. You are given a snippet of code that triggers the bug and a description of the bug.\n",
    "The bug reports are categorized as follows:'code-simplification-optimization-defects','control-flow-optimization-defects','data-flow-analysis-optimization-defects','infrastructure-defects','interprocedural-optimization-defects','memory-optimization-defects','numerical-analysis-optimization-defects','vectorization-defects'.\n",
    "You must select one of the above fourteen categories to output as the category of bug report.\n",
    "### Code Snippet:\n",
    "{data_point[\"code\"]}\n",
    "### Bug Description:\n",
    "{data_point[\"report\"]}\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    # Tokenize整个prompt\n",
    "    tokenized_prompt = tokenizer(full_prompt)\n",
    "    token_length = len(tokenized_prompt['input_ids'])\n",
    "\n",
    "    # 如果超过MAX_LENGTH，截断处理\n",
    "    if token_length > MAX_LENGTH:\n",
    "        # Tokenize code 和 input 部分\n",
    "        tokenized_code = tokenizer(data_point[\"code\"], truncation=False)\n",
    "        tokenized_input = tokenizer(data_point[\"report\"], truncation=False)\n",
    "\n",
    "        # 分别计算 code 和 input 的 token 长度\n",
    "        code_token_length = len(tokenized_code['input_ids'])\n",
    "        input_token_length = len(tokenized_input['input_ids'])\n",
    "\n",
    "        # 保留的长度 = MAX_LENGTH - (固定部分的token长度，即非code和input部分)\n",
    "        fixed_prompt = f\"\"\"You are a developer of the GCC compiler. Your job is to categorize bug reports. You are given a snippet of code that triggers the bug and a description of the bug.\n",
    "The bug reports are categorized as follows:'code-simplification-optimization-defects','control-flow-optimization-defects','data-flow-analysis-optimization-defects','infrastructure-defects','interprocedural-optimization-defects','memory-optimization-defects','numerical-analysis-optimization-defects','vectorization-defects'.\n",
    "You must select one of the above fourteen categories to output as the category of bug report.\n",
    "### Code Snippet:\n",
    "### Bug Description:\n",
    "### Response:\n",
    "\"\"\"\n",
    "        fixed_token_length = len(tokenizer(fixed_prompt)['input_ids'])\n",
    "        remaining_length = MAX_LENGTH - fixed_token_length\n",
    "\n",
    "        # 优先截断 code 和 input\n",
    "        if code_token_length + input_token_length > remaining_length:\n",
    "            # 如果总长度超过剩余长度，首先截断较长的部分\n",
    "            if code_token_length > input_token_length:\n",
    "                # 优先截断 code\n",
    "                truncated_code = tokenizer.decode(tokenized_code['input_ids'][:remaining_length - input_token_length])\n",
    "                truncated_input = data_point[\"report\"]\n",
    "            else:\n",
    "                # 优先截断 input\n",
    "                truncated_code = data_point[\"code\"]\n",
    "                truncated_input = tokenizer.decode(tokenized_input['input_ids'][:remaining_length - code_token_length])\n",
    "        else:\n",
    "            # 如果总长度不超标，不做额外截断\n",
    "            truncated_code = data_point[\"code\"]\n",
    "            truncated_input = data_point[\"report\"]\n",
    "\n",
    "        # 构建最终截断后的 prompt\n",
    "        full_prompt = f\"\"\"You are a developer of the GCC compiler. Your job is to categorize bug reports. You are given a snippet of code that triggers the bug and a description of the bug.\n",
    "The bug reports are categorized as follows:'code-simplification-optimization-defects','control-flow-optimization-defects','data-flow-analysis-optimization-defects','infrastructure-defects','interprocedural-optimization-defects','memory-optimization-defects','numerical-analysis-optimization-defects','vectorization-defects'.\n",
    "You must select one of the above fourteen categories to output as the category of bug report.\n",
    "### Code Snippet:\n",
    "{truncated_code}\n",
    "### Bug Description:\n",
    "{truncated_input}\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    # 进行最后的tokenize处理，确保token长度满足要求\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5476d3c-f199-4cc6-a35b-7d1d80351fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：提取生成文本中的分类结果\n",
    "\n",
    "import re\n",
    "def extract_predicted_label(response_text):\n",
    "    match = re.search(r'### Response:\\n\\s*([a-z-]+-defects)', response_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2daa35b-5eaf-48e2-a8e8-3e0ca554b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估三次，取最好的一次结果\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 初始化\n",
    "best_accuracy = 0.0\n",
    "best_predictions = []\n",
    "num_evaluations = 3\n",
    "\n",
    "for evaluation_round in range(num_evaluations):\n",
    "    print(f\"Starting evaluation {evaluation_round + 1}/{num_evaluations}\")\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(test_dataset, desc=f\"Evaluating Round {evaluation_round + 1}\"):\n",
    "            # 清理缓存以防止显存泄漏\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # 获取模型输入和标签\n",
    "            prompt = truncate(sample)  # 假设 truncate 是已定义的函数\n",
    "            true_label = sample[\"category\"]\n",
    "            model_input = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=5000).to(\"cuda\")\n",
    "            \n",
    "            # 模型生成输出\n",
    "            model_output = tokenizer.decode(model.generate(**model_input, max_new_tokens=30)[0], skip_special_tokens=True)\n",
    "            response = extract_predicted_label(model_output)  # 假设 extract_predicted_label 是已定义的函数\n",
    "\n",
    "            # 保存结果\n",
    "            true_labels.append(true_label)\n",
    "            predicted_labels.append(response)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    macro_f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    micro_f1 = f1_score(true_labels, predicted_labels, average='micro')\n",
    "    weighted_f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f\"Round {evaluation_round + 1} - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Round {evaluation_round + 1} - Macro F1 Score: {macro_f1:.4f}\")\n",
    "    print(f\"Round {evaluation_round + 1} - Micro F1 Score: {micro_f1:.4f}\")\n",
    "    print(f\"Round {evaluation_round + 1} - Weighted F1 Score: {weighted_f1:.4f}\")\n",
    "\n",
    "    # 保存当前轮次的最佳结果\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_predictions = predicted_labels\n",
    "        print(f\"New best accuracy found: {best_accuracy:.4f}\")\n",
    "\n",
    "# 保存最佳预测结果\n",
    "print(\"Evaluation completed.\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd58b2f-9f3a-4754-9e4e-f8fedeed89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(best_predictions)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150442a-7ab3-45d8-8740-f0821eb17e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "others = 'unknown'\n",
    "count = best_predictions.count(others)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ff017-812c-4db3-b0ac-d9cc774d1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = best_predictions.index(others)\n",
    "print(best_predictions[index])\n",
    "print(true_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd52b6d-36fb-4b9b-8134-c8844b6b3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions[index] = true_labels[index]\n",
    "best_predictions[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27826c36-30ed-4f2a-8279-935e2bc89df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 字符串到整数的映射字典\n",
    "label_mapping = {\n",
    "    'code-simplification-optimization-defects': 0,\n",
    "    'control-flow-optimization-defects': 1,\n",
    "    'data-flow-analysis-optimization-defects': 2,\n",
    "    'infrastructure-defects': 3,\n",
    "    'interprocedural-optimization-defects': 4,\n",
    "    'memory-optimization-defects': 5,\n",
    "    'numerical-analysis-optimization-defects': 6,\n",
    "    'vectorization-defects': 7\n",
    "}\n",
    "\n",
    "# 转换为整数列表\n",
    "predicted_labels_int = [label_mapping[label] for label in best_predictions]\n",
    "\n",
    "# 保存为元特征\n",
    "test_predictions_df = pd.DataFrame({\"llama_prediction\": predicted_labels_int})\n",
    "test_predictions_df.to_csv(\"data/ensemble/stacking/llama_predictions_v2-3.csv\", index=False)\n",
    "print(\"\\n预测结果已保存\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41d378-d6d9-48ff-bc37-87cd1bf0781f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0db11-ddd6-4448-924d-8bf3def69d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
